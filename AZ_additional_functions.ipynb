{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d779a654",
   "metadata": {},
   "source": [
    "*Alejandro Corrochano's contribution to the final project.* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cbc248be",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Common use \n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "import time\n",
    "\n",
    "#Metrics\n",
    "import sklearn.metrics as metrics\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "#RDKIT\n",
    "from rdkit import Chem\n",
    "\n",
    "#Feature selection\n",
    "from mrmr import mrmr_classif\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from skrebate import ReliefF\n",
    "from sklearn.feature_selection import mutual_info_regression, mutual_info_classif\n",
    "\n",
    "#Models - Regression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.svm import SVR\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "#Models - Classification\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39a8b1f5",
   "metadata": {},
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6486c508",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_overview(df, split):\n",
    "    print('Total number of molecules:',len(df))\n",
    "    print('Train set: %d - %0.1f%%' %(len(split['train']), len(split['train'])/len(df)*100))\n",
    "    print('Validation set: %d - %0.1f%%' %(len(split['valid']), len(split['valid'])/len(df)*100))\n",
    "    print('Test set: %d - %0.1f%%' %(len(split['test']), len(split['test'])/len(df)*100))\n",
    "    display(split['train'].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2cd05e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_comparison(names, met, c):\n",
    "    sns.set(font_scale = 1)\n",
    "    # set width of bar\n",
    "    barWidth = 0.15\n",
    "    plt.figure(figsize=(15, 6), dpi = 95)\n",
    "\n",
    "    # set height of bar\n",
    "    var1 = [i[0] for i in met]\n",
    "    var2 = [i[1] for i in met]\n",
    "    var3 = [i[2] for i in met]\n",
    "    if c == True:\n",
    "        var4 = [i[3] for i in met]\n",
    "        var5 = [i[4] for i in met]\n",
    "\n",
    "    # Set position of bar on X axis\n",
    "    br1 = np.arange(len(var1))\n",
    "    br2 = [x + barWidth for x in br1]\n",
    "    br3 = [x + barWidth for x in br2]\n",
    "    br4 = [x + barWidth for x in br3]\n",
    "    br5 = [x + barWidth for x in br4]\n",
    "\n",
    "    # Make the plot\n",
    "    if c == False:\n",
    "        plt.bar(br1, var1, color ='r', width = barWidth,\n",
    "                edgecolor ='grey', label ='R2')\n",
    "        plt.bar(br2, var2, color ='g', width = barWidth,\n",
    "                edgecolor ='grey', label ='MAE')\n",
    "        plt.bar(br3, var3, color ='b', width = barWidth,\n",
    "                edgecolor ='grey', label ='MSE')\n",
    "    \n",
    "    # Add 2 more bars \n",
    "    else :\n",
    "        plt.bar(br1, var1, color ='r', width = barWidth,\n",
    "                edgecolor ='grey', label ='MCC')\n",
    "        plt.bar(br2, var2, color ='g', width = barWidth,\n",
    "                edgecolor ='grey', label ='AUC')\n",
    "        plt.bar(br3, var3, color ='b', width = barWidth,\n",
    "                edgecolor ='grey', label ='ACC')\n",
    "        plt.bar(br4, var4, color ='yellow', width = barWidth,\n",
    "            edgecolor ='grey', label ='PRE')\n",
    "        plt.bar(br5, var5, color ='purple', width = barWidth,\n",
    "            edgecolor ='grey', label ='REC')\n",
    "    \n",
    "    # Adding Xticks\n",
    "    plt.xlabel('Models', fontweight ='bold', fontsize = 15)\n",
    "    plt.ylabel('Metrics', fontweight ='bold', fontsize = 15)\n",
    "    plt.xticks([r + barWidth for r in range(len(var1))],\n",
    "            [name for name in names])\n",
    "    plt.legend()\n",
    "    plt.title('Metrics obtained for each model')\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f9fdda48",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_reg_fs_metrics(num_sel_feat, results, fs_name):\n",
    "    \n",
    "    mse, r2 = [], []\n",
    "    for iteration in results:\n",
    "        mse.append(min([mse[2] for mse in iteration]))\n",
    "        r2.append(max([r2[0] for r2 in iteration]))\n",
    "    \n",
    "    # Plot R2 and MSE \n",
    "    plt.figure(figsize=(10, 4), dpi = 95)\n",
    "    sns.set_theme(style=\"darkgrid\")\n",
    "\n",
    "    sns.lineplot(x = np.arange(10, max(num_sel_feat)+5, 5), y = mse, marker='o', label = 'MSE')\n",
    "    sns.lineplot(x = np.arange(10, max(num_sel_feat)+5, 5), y = r2, marker='o', label = 'R2')\n",
    "    \n",
    "    # Vertical line to indicate best performance\n",
    "    sns.lineplot([num_sel_feat[np.argmax(r2)], num_sel_feat[np.argmax(r2)]], [0, max(mse)], \n",
    "                 color = 'red',linewidth = 4, label = 'Best')\n",
    "    plt.legend()\n",
    "    plt.title('MSE and R2 scores vs number of best features selected')\n",
    "    plt.xlabel('Number of selected features by %s'%fs_name)\n",
    "    plt.ylabel('Metrics')\n",
    "    plt.show()\n",
    "    return mse, r2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32dd5bbe",
   "metadata": {},
   "source": [
    "## Functionality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ae912e0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_ha_duplicates(df):\n",
    "    og_shape = df.shape\n",
    "    heavy_atoms = pd.Series([Chem.MolFromSmiles(smi).GetNumHeavyAtoms() for smi in df['Drug']])\n",
    "    # DF now only contains compounds with 5 or more heavy atoms\n",
    "    df = df[heavy_atoms >= 5]\n",
    "    # Duplicates removal from DF\n",
    "    df.drop(df[df['Drug'].duplicated()].index, inplace = True)\n",
    "    \n",
    "    print('Duplicated compounds and with less than 5 heavy atoms have been removed.')\n",
    "    print('New number of compounds: %d (%d)' %(df.shape[0], (df.shape[0] - og_shape[0])))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d233d85b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_val_test_split(df, split):\n",
    "    \n",
    "    # Training\n",
    "    X_train = df[df.columns[3:-1]][:len(split['train'])]\n",
    "    y_train = df['Y'][:len(split['train'])]\n",
    "    #Same with fingerprints (Since Y is the same, we just need to care of X)\n",
    "#     X_train_fps = fps[fps.columns[:]][:len(split['train'])]\n",
    "    \n",
    "    \n",
    "    # Validation\n",
    "    X_val = df[df.columns[3:-1]][len(split['train']):(len(split['valid'])+len(split['train']))]\n",
    "    y_val = df['Y'][len(split['train']):(len(split['valid'])+len(split['train']))]\n",
    "    #Same with fingerprints (Since Y is the same, we just need to care of X)\n",
    "#     X_val_fps = fps[fps.columns[:]][len(split['train']):(len(split['valid'])+len(split['train']))]\n",
    "\n",
    "    \n",
    "    # Test\n",
    "    X_test = df[df.columns[3:-1]][(len(split['valid'])+len(split['train'])):len(df)]\n",
    "    y_test = df['Y'][(len(split['valid'])+len(split['train'])):len(df)]\n",
    "    #Same with fingerprints (Since Y is the same, we just need to care of X)\n",
    "#     X_test_fps = fps[fps.columns[:]][(len(split['valid'])+len(split['train'])):len(df)]\n",
    "    \n",
    "    print('Data has been split')\n",
    "    \n",
    "    return X_train, y_train, X_val, y_val, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a06acff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove molecules that contain many zero-value/nan features\n",
    "def remove_nans(X_train, X_val, X_test, y_train, y_val, y_test):\n",
    "    for ind, dset in enumerate([X_train, X_val, X_test]):\n",
    "        nan_mols = dset.isnull().any(axis=1)\n",
    "        if len(dset[nan_mols].index) !=0 :\n",
    "            # Check rows where NaN values are located \n",
    "            nan_rows = dset[nan_mols].index\n",
    "            # Remove NaNs in dataset\n",
    "            dset.drop(index = nan_rows, inplace = True)\n",
    "            if ind == 0:\n",
    "                y_train.drop(index = nan_rows, inplace = True)\n",
    "#                 X_train_fps.drop(index = nan_rows, inplace = True)\n",
    "                print('Removed the following rows in the train set:',nan_rows)\n",
    "\n",
    "            elif ind == 1:\n",
    "#                 X_val_fps.drop(index = nan_rows, inplace = True)\n",
    "                y_val.drop(index = nan_rows, inplace = True)\n",
    "                print('Removed the following rows in the val set:',nan_rows)\n",
    "\n",
    "            else:\n",
    "                y_test.drop(index = nan_rows, inplace = True)\n",
    "                print('Removed the following rows in the test set:',nan_rows)\n",
    "        \n",
    "    return X_train, y_train, X_val, y_val, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "25ea5999",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_data(X_train, X_val, X_test):\n",
    "    scaler = StandardScaler()\n",
    "    \n",
    "    # convert in into DF after standardizing \n",
    "    X_train_norm = scaler.fit_transform(X_train)\n",
    "    X_train_norm = pd.DataFrame(X_train_norm, columns = X_train.columns)\n",
    "    \n",
    "    X_val_norm = scaler.transform(X_val)\n",
    "    X_val_norm = pd.DataFrame(X_val_norm, columns = X_val.columns)\n",
    "    \n",
    "    X_test_norm = scaler.transform(X_test)\n",
    "    X_test_norm = pd.DataFrame(X_test_norm, columns = X_test.columns)\n",
    "    \n",
    "    print('Data is now normalized.')\n",
    "    \n",
    "    return X_train_norm, X_val_norm, X_test_norm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4ebf6a7",
   "metadata": {},
   "source": [
    "### Feature selection algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "46d6d86b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fs_mrmr(X_train, y_train, X_val, y_val, X_train_norm, X_val_norm, c = False):\n",
    "    num_sel_feat = np.arange(10, X_train.shape[1], 5)\n",
    "    m,r,f = [], [], []\n",
    "    for k in num_sel_feat:\n",
    "        selected_features = mrmr_classif(X_train, y_train, K = k)\n",
    "        f.append(selected_features)\n",
    "        # Get metrics based on selected features\n",
    "        models, results = models_comparison(X_train[selected_features], y_train, X_val[selected_features], y_val,\n",
    "                                        c, False, False, X_train_norm[selected_features], X_val_norm[selected_features])\n",
    "        m.append(models)\n",
    "        r.append(results)\n",
    "    \n",
    "    return m,r,num_sel_feat,f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9c6cd4f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fs_score_fn(X_train, y_train, X_val, y_val, X_train_norm, X_val_norm, c, score_fn):\n",
    "    \n",
    "    num_sel_feat = np.arange(10, X_train.shape[1], 5)\n",
    "    \n",
    "    m,r,f = [], [], []\n",
    "    \n",
    "    for k in list(num_sel_feat):\n",
    "        print(\"\\n=======================Selected features %0.0f/%0.0f =======================\"%(k,X_train.shape[1]))\n",
    "        \n",
    "        # Applying feature selection algorithm supplied by the score_func on train, validation and normalized datasets\n",
    "        fs = SelectKBest(score_func=score_fn, k=k)         \n",
    "        fs.fit(X_train, y_train)\n",
    "                \n",
    "        # Retreive selected feature names\n",
    "        selected_features=X_train.columns[fs.get_support()]\n",
    "        \n",
    "        f.append(selected_features) \n",
    "        \n",
    "        # Get metrics based on selected features\n",
    "        models, results = models_comparison(X_train[selected_features], y_train, X_val[selected_features], y_val,\n",
    "                            c, False, False, X_train_norm[selected_features], X_val_norm[selected_features])\n",
    "        \n",
    "        m.append(models)\n",
    "        r.append(results)\n",
    "         \n",
    "    return m,r,num_sel_feat,f "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "66d777d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fs_relieff(X_train, y_train, X_val, y_val, X_train_norm, X_val_norm, c, n_neighbors):\n",
    "    \n",
    "    num_sel_feat = np.arange(10, X_train.shape[1], 5)\n",
    "    \n",
    "    m,r,f = [], [], []\n",
    "    \n",
    "    for k in list(num_sel_feat):\n",
    "        print(\"\\n=======================Selected features %0.0f/%0.0f =======================\"%(k,X_train.shape[1]))\n",
    "        # Applying relieff feature selection on train, validation and normalized datasets\n",
    "        fs = ReliefF(n_features_to_select=k, n_neighbors=n_neighbors)\n",
    "        \n",
    "        fs.fit_transform(X_train.to_numpy(), y_train.to_numpy())\n",
    "        pos = pd.DataFrame(fs.feature_importances_.reshape(-1,1)).sort_values(by=0, ascending=False).head(k).index.tolist()\n",
    "        selected_features = list(X_train.columns[pos])\n",
    "\n",
    "        f.append(selected_features) \n",
    "        \n",
    "        # Get metrics based on selected features\n",
    "        models, results = models_comparison(X_train[selected_features], y_train, X_val[selected_features], y_val,\n",
    "                            c, False, False, X_train_norm[selected_features], X_val_norm[selected_features])\n",
    "                \n",
    "        m.append(models)\n",
    "        r.append(results)\n",
    "        \n",
    "    return m,r,num_sel_feat,f "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e1b1d47",
   "metadata": {},
   "source": [
    "### Models comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "48a627c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute regression metrics \n",
    "def get_metrics(model_name, y_true, y_pred, c, train_times, mode = 0):\n",
    "    # Compute metrics \n",
    "    if c == False:\n",
    "        var1 = metrics.r2_score(y_true, y_pred)\n",
    "        var2 = metrics.mean_absolute_error(y_true, y_pred)\n",
    "        var3 = metrics.mean_squared_error(y_true, y_pred)\n",
    "        \n",
    "        print(model_name,'| R2: %0.3f, MAE: %0.3f, MSE: %0.3f | Training time: %0.1f' %(var1, var2, var3, train_times[-1]))\n",
    "        \n",
    "        # Mode to 1 displays r-squared plots\n",
    "        if mode == 1: \n",
    "            plt.figure(figsize=(10, 5), dpi = 95)\n",
    "\n",
    "            plt.scatter(y_true, y_pred, color='salmon', s=5)\n",
    "            plt.plot(np.unique(y_true), np.poly1d(np.polyfit(y_true, y_pred, 1))(np.unique(y_true)), color='black')\n",
    "\n",
    "            plt.text(0, 3.5,'R-squared = %0.2f' % var1)\n",
    "            plt.xlabel('Actual values')\n",
    "            plt.ylabel('Predicted Values')\n",
    "            plt.title('Prediction results using {}'.format(model_name))\n",
    "            plt.show()\n",
    "        \n",
    "        return var1, var2, var3\n",
    "        \n",
    "    else:\n",
    "        var1 = metrics.matthews_corrcoef(y_true, y_pred)\n",
    "        var2 = metrics.roc_auc_score(y_true, y_pred)\n",
    "        var3 = metrics.precision_score(y_true, y_pred)\n",
    "        var4 = metrics.recall_score(y_true, y_pred)\n",
    "        var5 = metrics.accuracy_score(y_true, y_pred)\n",
    "        \n",
    "        print(model_name,'| MCC: %0.3f, AUC: %0.3f, Accuracy: %0.3f, Precision: %0.3f, Recall: %0.3f | Training time: %0.1f' \n",
    "              %(var1, var2, var3, var4, var5, train_times[-1]))\n",
    "        \n",
    "    return var1, var2, var3, var4, var5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ea811760",
   "metadata": {},
   "outputs": [],
   "source": [
    "def models_comparison(X_train, y_train, X_val, y_val, c, plot = True, fps = False \n",
    "                          , X_train_norm = 0, X_val_norm = 0):\n",
    "    np.random.seed(10)\n",
    "    n_models = ['LR', 'RFR', 'DTR', 'SVR', 'MLPR', 'XGBR', 'MLPC', 'SVC', 'RFC', 'DTC', 'XGBC']\n",
    "    models = {'Regression': \n",
    "              {'Linear': {'LR': LinearRegression(), 'SVR': SVR(), \n",
    "                          'MLPR': MLPRegressor(hidden_layer_sizes=(128,64,32), max_iter=500)},\n",
    "               'Non-linear':{'RFR': RandomForestRegressor(), 'DTR': DecisionTreeRegressor(), 'SVR':SVR(), 'XGBR': XGBRegressor()}},\n",
    "                  \n",
    "              'Classification': \n",
    "              {'Linear': {'SVC': SVC(), \n",
    "                          'MLPC': MLPClassifier(hidden_layer_sizes=(128,64,32), max_iter=500)},\n",
    "               'Non-linear':{'RFC': RandomForestClassifier(), 'DTC': DecisionTreeClassifier(), 'XGBC': XGBClassifier()}}\n",
    "             }\n",
    "             \n",
    "\n",
    "    names, results, train_times = [], [], []\n",
    "\n",
    "    for name in n_models:\n",
    "        #REGRESSION\n",
    "        if name in models['Regression']['Linear'].keys() and c == False:\n",
    "            # Train the model and measure the time required\n",
    "            start_time = time.time()\n",
    "            clf = models['Regression']['Linear'][name].fit(X_train_norm, y_train)\n",
    "            train_time = time.time() - start_time\n",
    "            # Predict validation set values\n",
    "            y_pred = clf.predict(X_val_norm)\n",
    "            # Store the name of the model, metrics, and time for later visualization\n",
    "            names.append(name)\n",
    "            train_times.append(train_time)\n",
    "            r2, mae, mse = get_metrics(name, y_val, y_pred, c, train_times)\n",
    "            results.append([r2, mae, mse])\n",
    "            \n",
    "        elif name in models['Regression']['Non-linear'].keys() and c == False:\n",
    "            \n",
    "            start_time = time.time()\n",
    "            clf = models['Regression']['Non-linear'][name].fit(X_train, y_train)\n",
    "            train_time = time.time() - start_time\n",
    "            \n",
    "            y_pred = clf.predict(X_val)\n",
    "            \n",
    "            names.append(name)\n",
    "            train_times.append(train_time)\n",
    "            r2, mae, mse = get_metrics(name, y_val, y_pred, c, train_times)\n",
    "            results.append([r2, mae, mse])\n",
    "            \n",
    "            \n",
    "        #CLASSIFICATION\n",
    "        elif name in models['Classification']['Linear'].keys() and c == True:\n",
    "            start_time = time.time()\n",
    "            clf = models['Classification']['Linear'][name].fit(X_train_norm, y_train)\n",
    "            train_time = time.time() - start_time\n",
    "            \n",
    "            y_pred = clf.predict(X_val_norm)\n",
    "            \n",
    "            names.append(name)\n",
    "            train_times.append(train_time)\n",
    "            mcc, auc, acc, pre, rec = get_metrics(name, y_val, y_pred, c, train_times)\n",
    "            results.append([mcc, auc, acc, pre, rec])\n",
    "            \n",
    "        elif name in models['Classification']['Non-linear'].keys() and c == True :\n",
    "            start_time = time.time()\n",
    "            clf = models['Classification']['Non-linear'][name].fit(X_train, y_train)    \n",
    "            train_time = time.time()\n",
    "            \n",
    "            y_pred = clf.predict(X_val)\n",
    "\n",
    "            names.append(name)\n",
    "            train_times.append(train_time)\n",
    "            mcc, auc, acc, pre, rec = get_metrics(name, y_val, y_pred, train_times, c, train_times)\n",
    "            results.append([mcc, auc, acc, pre, rec])\n",
    "            \n",
    "            \n",
    "        else:\n",
    "            pass\n",
    "        \n",
    "    # We plot the metrics obtained for each model\n",
    "    if plot == True:\n",
    "        plot_comparison(names, results, c)\n",
    "    return names, results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b71c8630",
   "metadata": {},
   "source": [
    "### Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "35c7ec8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_randsearch(X_train, y_train, X_val, y_val, c, X_train_norm=0, X_val_norm=0):\n",
    "    np.random.seed(10)\n",
    "    \n",
    "    #---------------MODELS---------------------------------------\n",
    "    # REGRESSION\n",
    "    #RandomForestRegressor parameters\n",
    "    '''grid_param_rf = {\n",
    "         'n_estimators': [200, 250, 300],\n",
    "         'max_depth': [10, 20, 30, 40, None],\n",
    "         'max_features': ['auto', 'sqrt', 'log2'],\n",
    "         'min_samples_split': [2, 5, 10, 15],\n",
    "         'min_samples_leaf': [1, 2, 5, 10],\n",
    "         'bootstrap': [True, False]\n",
    "     }'''\n",
    "\n",
    "    #SVR parameters\n",
    "    grid_param_svm = {'kernel' : ['linear', 'poly', 'rbf', 'sigmoid'],\n",
    "                      'C' : [1,5,10],\n",
    "                      'degree' : [3,8],\n",
    "                      'coef0' : [0.01,10,0.5],\n",
    "                      'gamma' : ('auto','scale')\n",
    "                     }\n",
    "    \n",
    "    #XGBRegressor parameters\n",
    "    '''grid_param_xgb = { 'max_depth': [3, 5, 6, 10, 15, 20],\n",
    "           'learning_rate': [0.01, 0.1, 0.2, 0.3],\n",
    "           'subsample': np.arange(0.5, 1.0, 0.1),\n",
    "           'min_child_weight': [3, 5, 8, 10],\n",
    "           'colsample_bytree': np.arange(0.4, 1.0, 0.1),\n",
    "           'colsample_bylevel': np.arange(0.4, 1.0, 0.1),\n",
    "           'n_estimators': [100, 200, 500, 700, 1000]}'''\n",
    "\n",
    "    #--------------------------------------------------------------------------\n",
    "    \n",
    "    rnd_models = []\n",
    "    if c is True:\n",
    "         #[(grid_param_svm, SVC(), 1), (grid_param_rf, RandomForestClassifier(), 1), (grid_param_xgb, XGBClassifier(), 1)]\n",
    "        params = [(grid_param_svm, SVC(), 0)]\n",
    "    else:\n",
    "        #[(grid_param_svr, SVR(), 1), (grid_param_rf, RandomForestRegressor(), 1), (grid_param_xgb,XGBRegressor(), 1)]\n",
    "        params = [(grid_param_svm, SVR(), 1)]\n",
    "    \n",
    "    for grid in params:\n",
    "        random_config = RandomizedSearchCV(grid[1], param_distributions = grid[0], n_iter = 20, cv = 5, n_jobs = -1)\n",
    "        rnd_models.append((random_config, grid[2]))\n",
    "      \n",
    "    # Fit all the models and store their predictions\n",
    "    y_preds = []\n",
    "    for ind, m in enumerate(rnd_models):\n",
    "        # Make a distinction between linear and non linear models, 1 and 0 respectively \n",
    "        if m[1] == 0:\n",
    "            rnd_models[ind] = m[0].fit(X_train, y_train)\n",
    "            temp_clf = rnd_models[ind].best_estimator_\n",
    "            print(rnd_models[ind].best_params_)\n",
    "            y_preds.append(temp_clf.predict(X_val))\n",
    "            \n",
    "        elif m[1] == 1:\n",
    "            rnd_models[ind] = m[0].fit(X_train_norm, y_train)\n",
    "            temp_clf = rnd_models[ind].best_estimator_\n",
    "            print(rnd_models[ind].best_params_)\n",
    "            y_preds.append(temp_clf.predict(X_val_norm))\n",
    "    \n",
    "    #METRICS\n",
    "    if c is True:\n",
    "        #Compute classification metrics \n",
    "        mcc = metrics.matthews_corrcoef(y_true, y_pred)\n",
    "        auc = metrics.roc_auc_score(y_true, y_pred)\n",
    "        prec = metrics.precision_score(y_true, y_pred)\n",
    "        rec = metrics.recall_score(y_true, y_pred)\n",
    "        acc = metrics.accuracy_score(y_true, y_pred)\n",
    "        #Store metrics to return them later\n",
    "        mets = (mcc, auc, prec, rec, acc)\n",
    "        print('MCC: %f, AUC: %f, PRECISION: %f, RECALL: %f, ACCURACY: %f' %(mcc, auc, prec, rec, acc))\n",
    "    else:\n",
    "        #Compute regression metrics \n",
    "        for preds in y_preds:\n",
    "            r2 = metrics.r2_score(y_val, preds)\n",
    "            mae = metrics.mean_absolute_error(y_val, preds)\n",
    "            mse = metrics.mean_squared_error(y_val, preds)\n",
    "            #Store metrics to return them later\n",
    "            mets = (r2, mse, mae)\n",
    "            print('R2: %f, MSE: %f, MAE: %f' %(r2, mse, mae))\n",
    "\n",
    "    return rnd_models, mets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "676f7580",
   "metadata": {},
   "source": [
    "### Fingerprints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5e11127a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FP_data = (num_mols x numVectorBits)\n",
    "def generate_fingerprints(mol, fp_type=\"ECFP\", r = 2, bits =1024):\n",
    "    fp_arr = np.zeros((1,))\n",
    "    DataStructs.ConvertToNumpyArray(AllChem.GetMorganFingerprintAsBitVect(mol,r,bits),fp_arr)    \n",
    "    return fp_arr\n",
    "\n",
    "# Generate fingerprints dataset and transform into a dataframe\n",
    "# fps = pd.DataFrame([generate_fingerprints(Chem.MolFromSmiles(mol)) for mol in df['Drug']],columns = np.arange(1,1025))\n",
    "# print('Shape of the actual fps structure:', fps.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
